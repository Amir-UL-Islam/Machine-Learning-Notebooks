{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cd69a5f-0d5b-4e43-8495-9054496b21d9",
   "metadata": {},
   "source": [
    "### What is convolution?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b2528c-cd04-41f9-8746-a5a7314fc698",
   "metadata": {},
   "source": [
    "#### A convolution of an **one-dimensional array with a kernel comprises of taking the kernel, sliding it along the array, multiplying** it with the items in the array that overlap with the kernel in that location and summing this product."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae2c5ce-0730-4281-8203-ea76c0e6fc01",
   "metadata": {},
   "source": [
    "#### The convolution of an image with a kernel **summarizes a part of the image** as the sum of the multiplication of that part of the image with the kernel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34beb6b5-b950-4111-9da4-1f58fb8de37d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-13 02:37:12.857587: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4a1cd55-13d6-4b92-85a3-c18d106d054a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 1 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "array = np.array([0, 0, 0, 0, 0, 1, 1, 1, 1, 1])\n",
    "kernel = np.array([-1, 1]) # Changes\n",
    "\n",
    "conv = np.array([0, 0, 0, 0, 0, 0 ,0, 0, 0])\n",
    "\n",
    "for i in range(len(conv)):\n",
    "    conv[i] = (kernel*array[i: i+2]).sum()\n",
    "print(conv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4210e818-3c2b-478e-bbc2-6608c499b1ca",
   "metadata": {},
   "source": [
    "### Defining image convolution kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbfe22a-c103-46da-b18b-fb61b3014167",
   "metadata": {},
   "source": [
    "#### Convolutional networks for classification are constructed from a sequence of convolutional layers (for image processing) and fully connected (Dense) layers (for readout)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf93a71-6b0c-4875-9e59-639e67e868ca",
   "metadata": {},
   "source": [
    "### 2d convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f9c777f9-f3db-4c62-bd4a-637ca02ba845",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "image = [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]\n",
    "\n",
    "kernel = np.array([[-1, 1],[-1, 1]])\n",
    "\n",
    "conv2 = np.zeros([27, 27])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aa96e2ea-0c20-4b3e-95c8-bf8ec2a83f65",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_15880/191147766.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m27\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m27\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mconv2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "for i in range(27):\n",
    "    for j in range(27):\n",
    "        conv2[i, j] = (kernel*image[i: i+2, j: j+2]).sum()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19d099ce-4064-4011-9d58-392c7b82fec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-13 02:37:14.212566: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(10, kernel_size=3, activation='relu',padding='same', strides=2)) # total input = kernel_size*layer_unit\n",
    "#                                                                     = (3*3)*10\n",
    "#                                                                     = 90\n",
    "model.add(Flatten())\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9badd6-1903-46a9-88fd-ebfefb4ff8a0",
   "metadata": {},
   "source": [
    "### Diagram for the Network\n",
    "![cnn](imageNotes/cnn.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e72664ca-3d5d-4e55-a3c6-a334af6ea851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilation\n",
    "model.compile(optimizer='adam',\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3858b9f4-e504-493a-930a-9b18865a214d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fit the model on a training set\n",
    "# model.fit(train_data, train_labels, \n",
    "#           validation_split=0.2, \n",
    "#           epochs=3, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e14bcd-c8be-45b7-94e9-85265042a853",
   "metadata": {},
   "source": [
    "### Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b6b4ef-076e-42bb-b306-195adff22247",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4facaa-89bb-46e5-b186-a9ac9443b51e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f11a04-d0e7-47d3-a127-c6db393a6bda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ac8528-876b-4d07-8ea7-a14b5783cc21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2671d349-6868-4d0f-92bf-8074843eaa20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6727a7-3536-430b-a11c-5013099c021e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfe8a2d-3afa-4546-851f-361e6972a586",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c29911-ed13-4d83-90c4-686130b8f088",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb147fb-d918-4f5c-9c84-b7eedfcdd7d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
